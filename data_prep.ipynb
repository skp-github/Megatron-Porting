{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/Megatron-LM.git\n",
    "%cd Megatron-LM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install transformers datasets huggingface_hub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from huggingface_hub import snapshot_download\n",
    "from datasets import load_dataset\n",
    "from megatron.core.tokenizers import MegatronTokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "ds = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "dataset = ds.select(range(10000))\n",
    "with open(\"data/tinystories_train.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in dataset:\n",
    "        f.write(json.dumps({\"text\": row[\"text\"]}) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tok_dir = snapshot_download(\n",
    "    repo_id=\"gpt2\",\n",
    "    allow_patterns=[\n",
    "        \"tokenizer.json\", \"vocab.json\", \"merges.txt\",\n",
    "        \"tokenizer_config.json\", \"special_tokens_map.json\", \"*.model\"\n",
    "    ]\n",
    ")\n",
    "MegatronTokenizer.write_metadata(\n",
    "    tokenizer_path=tok_dir,\n",
    "    tokenizer_library=\"huggingface\",\n",
    "    metadata_path=os.path.join(\"data/\", \"tokenizer_metadata.json\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python tools/preprocess_data.py \\\n",
    "  --input data/tinystories_train.jsonl \\\n",
    "  --json-keys text \\\n",
    "  --output-prefix data/tinystories_meg \\\n",
    "  --tokenizer-type HuggingFaceTokenizer \\\n",
    "  --tokenizer-model gpt2 \\\n",
    "  --append-eod \\\n",
    "  --workers 8"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
